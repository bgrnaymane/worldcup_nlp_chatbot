{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "#nlp Libraries\n",
    "from odenet import *\n",
    "import spacy\n",
    "from spacy.lang.de.examples import sentences \n",
    "nlp = spacy.load(\"de_core_news_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "synonyms_word(\"platzierung\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new intents as dictionary\n",
    "data = dict()\n",
    "data['Soccer_Intents'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data['Soccer_Intents'])):\n",
    "        \n",
    "    intent = data['Soccer_Intents'][i]\n",
    "    tag = intent['tag']\n",
    "    pattern = intent['patterns']\n",
    "\n",
    "    \n",
    "    #single words like headache\n",
    "    \n",
    "    #get synonyms for the tag\n",
    "    synonyms = wordnet.synsets(tag)\n",
    "    new_words = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "    new_words = [word.replace('_', ' ') for word in new_words] #this is a list with every synonym found by the wordnet from nltk\n",
    "    \n",
    "    docs = []\n",
    "    for item in new_words:\n",
    "        \n",
    "        #filter out synonyms that have no scientific background\n",
    "        #note that this step was due to weird synonyms like \"make out\" as a synonym for \"neck\" (the body part)\n",
    "        #we only could use a scientific dataset from sci-spacy but would have favored a medical dataset here. (More on that at the end)\n",
    "        doc = list(nlp(item).ents)\n",
    "\n",
    "        X = []\n",
    "        for x in doc:\n",
    "            x = str(x)\n",
    "            X.append(x)\n",
    "\n",
    "        X = ' '.join(X)\n",
    "        docs.append(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    pattern.extend(docs)\n",
    "    \n",
    "    #two words like neck_pain\n",
    "    #same process es above but for each of the two words we find synonyms each, then filter them and then combine them to one pattern.\n",
    "    sentence = tag.split('_')\n",
    "    if len(sentence) == 2:\n",
    "        liste=[]\n",
    "        for part in sentence:\n",
    "            synonyms = wordnet.synsets(part)\n",
    "            part = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "            part = [word.replace('_', ' ') for word in part]\n",
    "\n",
    "            docs= []\n",
    "            for item in part:\n",
    "                doc = list(nlp(item).ents)\n",
    "\n",
    "                X = []\n",
    "                for x in doc:\n",
    "                    x = str(x)\n",
    "\n",
    "                    X.append(x)\n",
    "                    \n",
    "                X = ' '.join(X)\n",
    "                docs.append(X)\n",
    "\n",
    "            liste.append(docs)\n",
    "\n",
    "        liste2=[]\n",
    "        for part in liste:\n",
    "            part = [x for x in part if x]\n",
    "            liste2.append(part)\n",
    "\n",
    "        liste2 = list(itertools.product(liste2[0], liste2[1]))\n",
    "        \n",
    "        for sentence in liste2:\n",
    "            string = ' '.join(sentence) \n",
    "\n",
    "            pattern.append(string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pattern' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-477597b368b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pattern' is not defined"
     ]
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pattern' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fe963d411c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#add pattern and the belonging tag/intent/synonym to the intents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pattern' is not defined"
     ]
    }
   ],
   "source": [
    "    #add pattern and the belonging tag/intent/synonym to the intents\n",
    "\n",
    "pattern = list(set(pattern))\n",
    "    \n",
    "dictionary = dict()\n",
    "dictionary['tag']=tag\n",
    "dictionary['patterns']=pattern\n",
    "    \n",
    "data['intents'].append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save intents as new intents\n",
    "json_object = json.dumps(data, indent = 4)\n",
    "\n",
    "with open(\"intents_new2.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ed9318c1c5e4abbf8521e4ed5dfc5eb2c4910171559febde90d790edebda5b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
