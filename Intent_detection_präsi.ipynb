{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import log_loss\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nltk\n",
    "import ssl\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating own Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'query':['Which team became 6th place in 2006?', 'Which team was world champion in the year 2010?', 'Who won in 1990?', 'Who was the winner in 1934?',\n",
    "        'Who became the world champion in 1938?', 'Which team won in 1974?', 'Which team was on the 5th place in the worldcup in 1950?',\n",
    "        'Who got the 2nd place in 1986?', 'Who was the world-champion in the world-championship of 2018?', 'Which team is the champion of the year 2002?',\n",
    "\n",
    "        'On which position was Germany in 1986?', 'Brasil got which place in 2014?', 'Which place was Morroco on in 2022?', 'What was the ranking of Sweden in 1958?', \n",
    "        'On which place did the Netherlands land on in the year 1974?', 'What was the placement of Italy in 1938?', 'What ranking did England have in the world-championship of 2010?',\n",
    "        'What was Spain\\'s ranking in 2018?', 'What was the placement of Poland in 2002?', 'Which place did France get in the worldcup 2018?',\n",
    "\n",
    "        'Who hosted the world cup in the year 2018?', 'Which nation was the host of the world cup in 1950?', 'Where was the world cup 1958?', 'Where was the world cup held in 1958?',\n",
    "        'Who was the host of the world-championship in 2002?', 'Which country hosted the world cup in the year 1978?', 'Where was the world cup held in 1990?',\n",
    "        'Where did the world cup take place in the year 2006?', 'Who has hosted the worldcup in 1974?', 'In which country did the world cup take place in 2022?',\n",
    "\n",
    "        'On average, how many goals were scored in 1998?', 'How many goals were scored in the world-championship of 1962 on average?', 'What were the average goals scored in 1986?', 'What was the average number of goals scored in 1930?',\n",
    "        'What was the average of goals in 1974?', 'How many goals have been scored on average in the year 2002? ', 'How many goals were scored on average in 1990?',\n",
    "        'In the worldcup 1962, how many goals have been scored on average?', 'What was the average number of goals scored in the year 1962?', 'What was the average number of goals in 1938?',\n",
    "\n",
    "        'How many goals were scored 1950?', 'How many goals in the world-championship of 2010?', 'What is the number of overall goals in 2022?', 'How many goals were made in 2002?',\n",
    "        'How many goals were accumulated in 2018?', 'What was the total of goals in 1960?', 'What was the total number of goals in 1930?',\n",
    "        'What is the sum of all goals scored in the year 1938?', 'What is the total number of goals scored in the worldcup of 1950?', 'How many goals were scored in the world cup in 1990?',\n",
    "\n",
    "        'How many matches were played in the world-championship of 1930?','What is the number of matches played in 1954?','What was the amount of matches in the 2010 worldcup?', 'How many matches were played in Germany in 2006?',\n",
    "        'What is the total number of games played in the year 2002?', 'What is the sum of matches played in 1974?', 'In 2018, how many matches took place?',\n",
    "        'How many matches have been played in 1950?', 'How many games were played in 1974?', 'What is the total of matches played in 1978?',\n",
    "\n",
    "        'won','winner','champion ','world champion','world-champion','first place',\n",
    "        'Who won the world cup in 1974?', 'Who was world-champion in 1950?', 'Who got the first place of the world cup in 2002?',\n",
    "        'Who was the winner of the world-championship in 2006?', 'Who was the champion of the worldcup in 2010?',\n",
    "\n",
    "        'Hello.', 'Hellooo', 'Hi!', 'Hey,', 'Heyyy,', 'Good day!', 'Good evening.',\n",
    "\n",
    "        'Thank you!', 'Thanks', 'Thank you very much!', 'Okay, thanksie!',\n",
    "\n",
    "        'Goodbye', 'Bye', 'See you!', 'Byebyeee'],\n",
    "\n",
    "\n",
    "       'category':['PlacementTeam','PlacementTeam','PlacementTeam','PlacementTeam',\n",
    "       'PlacementTeam','PlacementTeam','PlacementTeam',\n",
    "       'PlacementTeam','PlacementTeam','PlacementTeam',\n",
    "\n",
    "       'TeamPlacement','TeamPlacement','TeamPlacement','TeamPlacement',\n",
    "       'TeamPlacement','TeamPlacement','TeamPlacement',\n",
    "       'TeamPlacement','TeamPlacement','TeamPlacement',\n",
    "\n",
    "       'YearHost','YearHost','YearHost','YearHost',\n",
    "       'YearHost','YearHost','YearHost',\n",
    "       'YearHost','YearHost','YearHost',\n",
    "\n",
    "       'year(avg)Goals','year(avg)Goals','year(avg)Goals','year(avg)Goals',\n",
    "       'year(avg)Goals','year(avg)Goals','year(avg)Goals',\n",
    "       'year(avg)Goals','year(avg)Goals','year(avg)Goals',\n",
    "\n",
    "       'yearGoals','yearGoals','yearGoals','yearGoals',\n",
    "       'yearGoals','yearGoals','yearGoals',\n",
    "       'yearGoals','yearGoals','yearGoals',\n",
    "\n",
    "       'yearMatches','yearMatches','yearMatches','yearMatches',\n",
    "       'yearMatches','yearMatches','yearMatches', \n",
    "       'yearMatches','yearMatches','yearMatches', \n",
    "\n",
    "       'firstPlace','firstPlace', 'firstPlace','firstPlace','firstPlace','firstPlace', \n",
    "       'firstPlace','firstPlace','firstPlace',\n",
    "       'firstPlace', 'firstPlace',\n",
    "       \n",
    "       'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting','greeting',\n",
    "       \n",
    "       'thankYou', 'thankYou', 'thankYou', 'thankYou', \n",
    "       \n",
    "       'bye', 'bye', 'bye', 'bye']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function for a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to train model with empty list at this point\n",
    "def train_model():\n",
    "    trained_model = ''\n",
    "    return trained_model\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent(input):\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    #necessary nltk and spacy package for the upcoming cleanup part\n",
    "    nltk.download('stopwords')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    punctuations = string.punctuation\n",
    "\n",
    "    #remove pronouns, stopwords, and puncuation as a definied function \n",
    "    def cleanup_text(docs, logging=False):\n",
    "        texts = [] \n",
    "        counter = 1\n",
    "        for doc in docs:\n",
    "            if counter % 1000 == 0 and logging:\n",
    "                print(\"Processed %d out of %d documents.\" % (counter, len(docs)))\n",
    "            counter += 1\n",
    "            doc = nlp(doc, disable=['parser', 'ner'])\n",
    "            tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-'] #Lemmatization and lowercasing\n",
    "            tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations] #removing stopwords\n",
    "            tokens = ' '.join(tokens)\n",
    "            texts.append(tokens)\n",
    "        return pd.Series(texts)\n",
    "    train_cleaned = cleanup_text(df['query'], logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # further cleaning to apply a word2vec model\n",
    "    def cleanup_text_word2vec(docs, logging=False):\n",
    "        sentences = []\n",
    "        counter = 1\n",
    "        for doc in docs:\n",
    "            if counter % 1000 == 0 and logging:\n",
    "                print(\"Processed %d out of %d documents\" % (counter, len(docs)))\n",
    "            doc = nlp(doc, disable=['tagger'])\n",
    "            doc = \" \".join([tok.lemma_.lower() for tok in doc])\n",
    "            doc = re.split(\"[\\.?!;] \", doc) #splitting text into sentences and words\n",
    "            doc = [re.sub(\"[\\.,;:!?]\", \"\", sent) for sent in doc]\n",
    "            doc = [sent.split() for sent in doc]\n",
    "            sentences += doc\n",
    "            counter += 1\n",
    "        return sentences #list of lists\n",
    "    train_cleaned_word2vec = cleanup_text_word2vec(df['query'], logging=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (v3.8.10:3d8993a744, May  3 2021, 08:55:58) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
